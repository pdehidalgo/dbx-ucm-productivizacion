{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](https://raw.githubusercontent.com/pdehidalgo/dbx-ucm-productivizacion/main/logo_ucm.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio: Evaluación de prompts con MLflow + Azure OpenAI + Telegram\n",
    "\n",
    "\n",
    "**Objetivo**: Construir ChatBot con Telegram que permita describir imágenes técnicas recibidas mediante el cliente de Telegram.\n",
    "Se deberán comparar múltiples prompts con MLflow, elegir el mejor (baśandose en un criterio a seleccionar razonadamente por el alumno) y luego usarlo para responder a imágenes enviadas desde un bot de Telegram.\n",
    "\n",
    "## Requisitos de entrega:\n",
    "\n",
    "- 1. Un script `main.py` funcional con el flujo completo\n",
    "- 2. Una imagen/captura de pantalla de MLflow con los prompts registrados y [evaluados](https://mlflow.org/docs/latest/model-evaluation/)\n",
    "- 3. Una imagen/captura de Telegram mostrando que se recibió una imagen y se respondió con la descripción del error\n",
    "\n",
    "## Recursos disponibles\n",
    "\n",
    "- Vídeo de la clase del Sábado 31 con la creación de un Servicio de Azure OpenAI para gpt-4o y Whispers. \n",
    "- Taller de mlflow para el despliegue en local en la documentación subida en Moodle. \n",
    "- Ejemplo de código funcional subido al repositorio del curso: ejemplo [end2end](https://github.com/pdehidalgo/dbx-ucm-productivizacion/blob/main/telegram_project/ejemplo_finalizado.py)\n",
    "\n",
    "### Paso 1. Preparar entorno, MLflow y las variables y APIs necesarias: \n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Configura tus variables de entorno (puedes usar dotenv si lo prefieres)\n",
    "endpoint = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "deployment = \"gpt-4o\"\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Paso 2. Definir prompts candidatos (al menos tres)\n",
    "\n",
    "```python\n",
    "prompts = [\n",
    "    \"Describe detalladamente lo que ves en la imagen, .....\",\n",
    "    \"Eres un técnico especializado. ....\",\n",
    "    \"Analiza visualmente la imagen y ...\"\n",
    "]\n",
    "\n",
    "image_path = \"sample_error.jpg\"  # Usa una imagen simulada de error técnico (puede ser una captura de pantalla con mensaje de error)\n",
    "\n",
    "```\n",
    "\n",
    "### Paso 3. Evaluar cada prompt con gpt-4o y registrar en MLflow\n",
    "\n",
    "```python\n",
    "def evaluate_prompt(prompt, image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = base64.b64encode(image_file.read()).decode()\n",
    "\n",
    "    result = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    ### Incluye aquí la/s imágene/s\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "mlflow.set_experiment(\"image-description-prompts\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    for prompt in prompts:\n",
    "        response = evaluate_prompt(prompt, image_path)\n",
    "        \n",
    "        # Incluye aquí tus métricas\n",
    "\n",
    "        mlflow.log_param(\"prompt\", prompt)\n",
    "        mlflow.log_metric(...)\n",
    "\n",
    "print(\"Evaluación de prompts completada. Verifica MLflow UI.\")\n",
    "```\n",
    "\n",
    "**Tip**: el código anterior sirve de ejemplo, utiliza métricas de evaluación propias de mlflow.evaluate o crea tu propia métrica, piensa en las implicaciones de crear un dataset sintético y comparar la salida del sistema con tu descripción creada sobre el error de la imagen. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Paso 4. Obtener mejor prompt registrado\n",
    "\n",
    "```python\n",
    "def get_best_prompt():\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    ## Crea tu criterio de ordenación\n",
    "    runs = client.search_runs(experiment_ids=[\"0\"], order_by=[\"metrics.clarity_score DESC\"])\n",
    "    return runs[0].data.params[\"prompt\"]\n",
    "```\n",
    "\n",
    "\n",
    "### Paso 5. Usar mejor prompt para responder imágenes vía Telegram\n",
    "\n",
    "Este código se incluirá en el archivo main.py junto con el bot. Usará el `get_best_prompt()` como prompt final.\n",
    "\n",
    "Implementa un nuevo endpoint sobre el código de `ejemplo_finalizado.py` que permita interactuar con imágenes. No olvides restringir el uso...\n",
    "\n",
    "```python\n",
    "@bot.message_handler(content_types=[\"photo\"])\n",
    "def on_photo(message):\n",
    "    user_id = message.chat.id\n",
    "    file_info = bot.get_file(...Interactúa con la imagen...)\n",
    "    file = requests.get(f\"https://api.telegram.org/file/bot{os.getenv('TELEGRAM_BOT_TOKEN')}/{file_info.file_path}\")\n",
    "\n",
    "    \n",
    "    # Llamada al asistente usando el mejor prompt y la imagen\n",
    "\n",
    "    description = ...\n",
    "\n",
    "    bot.send_message(user_id, f\"Diagnóstico:\\n{description}\")\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuerda:\n",
    "- Ejecuta `mlflow ui` en tu entorno para levantar la interfaz local\n",
    "- Registra los resultados de cada prompt\n",
    "- Usa `get_best_prompt()` para consultar el mejor prompt en tu bot Telegram\n",
    "\n",
    "### Entrega esperada:\n",
    "- main.py con flujo Telegram + OpenAI\n",
    "- Imagen del dashboard MLflow mostrando parámetros y métricas\n",
    "- Captura del bot Telegram recibiendo imagen y respondiendo diagnóstico\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
